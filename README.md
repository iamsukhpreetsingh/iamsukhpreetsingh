<div align="center">

# Hi there! 👋 I'm Sukhpreet Singh

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Let's_Connect-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/sukhpreet41/)
[![Email](https://img.shields.io/badge/Email-Drop_a_Line-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:isukhpreetsingh12@gmail.com)
[![Resume](https://img.shields.io/badge/Resume-Download_Now-4CAF50?style=for-the-badge&logo=adobeacrobatreader&logoColor=white)](https://drive.google.com/drive/folders/1eYrM5aKGdqq_lF8Vpm3H4MnTLovNV7gu)


</div>

---

## 🎯 About Me

I'm a **Data Engineer Intern** at SparkBrains, building expertise in data pipelines, cloud technologies, and analytics. 
- 🔭 Currently working on: **PySpark, AWS, Snowflake, SQL, Data Transformations**
- 🌱 Learning: **Apache Kafka, Advanced SQL, Cloud Architecture**
- 💬 Ask me about: **Data pipelines, Python, SQL**

---

## 📁 Projects

| Project Name | Technologies used | Link |
|--------------|-------------|------|
| **Project 1: Enviornment Data Refresh Automation POC** | Snowflake, AWS | [View Project](https://github.com/iamsukhpreetsingh/snowflake_project/tree/main/enviornment_refresh_automation) |
| **Project 2: Secure Data Sharing POC** | Snowflake, AWS | [View Project](https://github.com/sukhpreet-sparkbrains/data_engineering/tree/main/Snowflake_projects_and_POCs/secure_data_sharing) |
| **Project 3: Snowflake and DBT implemetation POC** | Snowflake, AWS, DBT | [View Project](https://github.com/iamsukhpreetsingh/snowflake_project/tree/main/Snowflake_dbt_POC) |



---
## 💼 Work Experience:
### 🏢 SparkBrains - Data Engineer Intern
📅 May 2025 - Present

**Tech Stack:** `PySpark` `Python` `SQL` `PostgreSQL`

### Roles & Responsibilities:

- Write Complex Transformations using PySpark to process large volumes of structured and semi-structured data from diverse sources.
- Write SQL queries for data extraction, transformation, and loading tasks across various relational and distributed data systems.
- Assist in data quality checks and validation by implementing logic to handle nulls, duplicates, schema mismatches, and other inconsistencies during data ingestion.
- Collaborate with data analysts and senior engineers to understand business requirements and ensure the data infrastructure supports reporting and analytics.

---
### 🏢 Kontinuum Kode - Business Development Executive
📅 June 2024 - April 2025

### Roles & Responsibilities:

- Lead Generation through portals like UpWork and PeoplePerHour.
- Tailored Proposal Writing.
- Creating SRS & BRD Documents.

---

## 🤝 Let's Connect!

Always excited to collaborate on data projects or discuss the latest in data engineering!

