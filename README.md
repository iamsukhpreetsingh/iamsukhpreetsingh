<div align="center">

# Hi there! üëã I'm Sukhpreet Singh

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Let's_Connect-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/sukhpreet41/)
[![Email](https://img.shields.io/badge/Email-Drop_a_Line-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:isukhpreetsingh12@gmail.com)
[![Resume](https://img.shields.io/badge/Resume-Download_Now-4CAF50?style=for-the-badge&logo=adobeacrobatreader&logoColor=white)](https://drive.google.com/drive/folders/1eYrM5aKGdqq_lF8Vpm3H4MnTLovNV7gu)


</div>

---

## üéØ About Me:

I am a **SnowPro Associate‚Äìcertified** Junior Data Engineer with hands-on experience in building ETL/ELT pipelines, leveraging technologies like `PySpark`, `SQL`, `AWS`, `DBT` and `Snowflake` to transform raw data into actionable insights. 

Core Competencies: Data Pipeline Development ‚Ä¢ Cloud Architecture ‚Ä¢ Data Modeling ‚Ä¢ Performance Optimization ‚Ä¢ Cross-functional Collaboration

---

## üèÜ Certifications:
- [SnowPro Associate - Snowflake](https://achieve.snowflake.com/eb7ff57a-6c21-4eb5-9b8d-9c1f0ac051ec#acc.OEDkA9lR)


---

## Professional Experience:
### Junior Data Engineer | SparkBrains
üìÖ May 2025 - Present

**Tech Stack:** `SQL` `PySpark` `Snowflake` `Python` `PostgreSQL`

### Roles & Responsibilities:

- Developing SQL and PySpark scripts to build aggregated views in Hive, enabling the BI team to generate accurate business insights.
- Designing and implemented staging ETL data pipelines using PySpark and Jupyter Notebooks, integrating data from diverse sources including APIs, JSON, Excel, and CSV files, and loading them into HDFS.
- Performing data unification and integration tasks in the staging environment, improving data consistency and reliability across systems.
- Preforming data mapping from diverse sources data like advertisement, suppliers, imports/exports data, etc and preforming data validations on the given data.
- Appling PySpark-based data transformation techniques to cleanse, normalize, and enrich large-scale datasets, ensuring high-quality data for downstream analytics.

---
### Business Development Executive | Kontinuum Kode
üìÖ June 2024 - April 2025

### Roles & Responsibilities:

- Generated 70+ qualified leads through strategic outreach on Upwork and PeoplePerHour platforms.
- Crafted technical proposals and maintained client relationships resulting in 5 successful project acquisitions.
- Authored comprehensive SRS (Software Requirements Specification) and BRD (Business Requirements Document) documentation.

---

## üìÅ Personal Projects/POCs:

| Project Name | Technologies used | Link |
|--------------|-------------|------|
| **Project 1: End-to-End API & XML data pipeling POC** | Postgres, SQL, Python, XML, JSON | [View Project](https://github.com/iamsukhpreetsingh/etl_api_xml) |
| **Project 2: Secure Data Sharing POC** | Snowflake, AWS | [View Project](https://github.com/sukhpreet-sparkbrains/data_engineering/tree/main/Snowflake_projects_and_POCs/secure_data_sharing) |
| **Project 3: Snowflake and DBT implemetation POC** | Snowflake, AWS, DBT | [View Project](https://github.com/iamsukhpreetsingh/snowflake_project/tree/main/Snowflake_dbt_POC) |


---

## üéì Education:
Bachelor of Engineering (B.E.) in Computer Science
Chandigarh University | 2020-2024



## ü§ù Let's Connect!

Always excited to collaborate on data projects or discuss the latest in data engineering!

